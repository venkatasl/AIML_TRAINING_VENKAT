{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatasl/AIML_TRAINING_VENKAT/blob/venkat_creation/DRDO2024_FeatureInversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature inversion\n",
        "\n",
        "What does a model see when it looks at an image? This is what we find out using feature inversion.\n",
        "\n",
        "We take the features of the model at a particular layer and try to reconstruct the input image from it."
      ],
      "metadata": {
        "id": "tIYjmUO5_nAq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKLaAKoB6uX4"
      },
      "outputs": [],
      "source": [
        "# import everything\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.v2 as v2\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "gpu = False # turn to True if using a gpu kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# put the model on the gpu\n",
        "if gpu:\n",
        "  model.cuda()\n"
      ],
      "metadata": {
        "id": "bdI6ly6y_8Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 has 39 layers in total. Let us write a function to propagate an input forward to the desired layer and get the features from there.\n",
        "\n"
      ],
      "metadata": {
        "id": "g_vRew0lBw_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(model, input, layernum):\n",
        "  index = 0\n",
        "  for layer in model.features.children():\n",
        "    input = layer(input)\n",
        "    if index==layernum:\n",
        "      return input\n",
        "    index += 1\n",
        "\n",
        "  input = model.avgpool(input)\n",
        "  if index==layernum:\n",
        "    return input\n",
        "  index += 1\n",
        "\n",
        "  input = torch.flatten(input, 1)\n",
        "\n",
        "  for layer in model.classifier.children():\n",
        "    input = layer(input)\n",
        "    if index==layernum:\n",
        "      return input\n",
        "    index += 1\n",
        "  return index # if layernum is bigger than the number of layers, it will return how many layers are there\n"
      ],
      "metadata": {
        "id": "6IqwBVobADTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define some helper functions:"
      ],
      "metadata": {
        "id": "eAx4bGb3DaTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image transformation. This is important because this is how the model was trained\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    # The below values are based on the mean and st.deviation of the ImageNet dataset\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# inverse of the preprocess transform\n",
        "inversetransform = transforms.Compose([\n",
        "        transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "    std=[1/0.229, 1/0.224, 1/0.255]),\n",
        "        transforms.ToPILImage()])\n",
        "\n",
        "# Function to load and preprocess the image\n",
        "def load_image(image_path, display=False):\n",
        "    if image_path.startswith('http'):\n",
        "        response = requests.get(image_path)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "    else:\n",
        "        img = Image.open(image_path)\n",
        "    img = preprocess(img)\n",
        "    if display:\n",
        "      plt.imshow(inversetransform(img))\n",
        "\n",
        "    img = img.unsqueeze(0)  # Add batch dimension\n",
        "    return img"
      ],
      "metadata": {
        "id": "YKGbRIzAALE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define some loss functions and regularization functions:"
      ],
      "metadata": {
        "id": "PNYflwjYHQTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tv(t,beta=2):\n",
        "    #gets the smoothness or the edginess of an image\n",
        "    tv_x = t[:,:,:,1:]-t[:,:,:,:-1]\n",
        "    tv_y = t[:,:,1:,:]-t[:,:,:-1,:]\n",
        "\n",
        "    tv_x = tv_x[:,:,:-1,:]\n",
        "    tv_y = tv_y[:,:,:,:-1]\n",
        "    if False: print(tv_x)\n",
        "    tv_2 = tv_x **2 + tv_y **2\n",
        "    tv = tv_2.pow(beta/2.)\n",
        "    total = tv.sum()\n",
        "    return total\n",
        "\n",
        "def tv2(t):\n",
        "    #specifically with beta =2\n",
        "    tv_x = t[:,:,:,1:]-t[:,:,:,:-1]\n",
        "    tv_y = t[:,:,1:,:]-t[:,:,:-1,:]\n",
        "\n",
        "    tv_x = tv_x[:,:,:-1,:]\n",
        "    tv_y = tv_y[:,:,:,:-1]\n",
        "    tv_x_2 = (tv_x **2).sum()\n",
        "    tv_y_2 = (tv_y **2).sum()\n",
        "\n",
        "    if False: print(tv_x)\n",
        "    tv_2 =  tv_x_2 + tv_y_2\n",
        "    total = tv_2.sum()\n",
        "    return total\n",
        "\n",
        "def alpha_norm(t,alpha=6):\n",
        "    a = torch.sum(t.pow(alpha))\n",
        "    return a\n",
        "\n",
        "def mse(ref, x):\n",
        "    return torch.nn.functional.mse_loss(ref,x)\n",
        "\n",
        "def total(ref_feat, x_feat, x, alpha_lambda, tv_lambda ):\n",
        "    return mse(ref_feat,x_feat) + alpha_lambda*alpha_norm(x) + tv_lambda*tv2(x);\n",
        "    #return mse(ref_feat, x_feat)\n",
        "\n"
      ],
      "metadata": {
        "id": "8c5U1GenA2vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inversion function:"
      ],
      "metadata": {
        "id": "RT_llTIiJl_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_image(model, input, layernum, alpha_lambda, tv_lambda,lr, iterations=1000):\n",
        "  x = torch.rand(1,3,224,224) # this is the random image we will optimize\n",
        "  if gpu:\n",
        "    x = x.cuda()\n",
        "  x.requires_grad=True\n",
        "  optimizer = Adam([x], lr=0.5, weight_decay=1e-6) # create an optimizer for the image\n",
        "\n",
        "  # get the reference features\n",
        "  ref_feats = get_features(model, input, layernum).detach() # don't want to keep extra gradients\n",
        "\n",
        "  # let us optimize for a 1000 steps\n",
        "  for i in range(iterations):\n",
        "    x_feats = get_features(model, x, layernum)\n",
        "    loss = total(ref_feats, x_feats, x , alpha_lambda, tv_lambda)\n",
        "    optimizer.zero_grad();\n",
        "    loss.backward()\n",
        "    optimizer.step();\n",
        "    print(f'\\r {i} of {iterations} iterations complete', end = '     ')\n",
        "\n",
        "  return inversetransform(x.squeeze())"
      ],
      "metadata": {
        "id": "XCUY5IR_D-ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try it with an image!"
      ],
      "metadata": {
        "id": "CbwIaVn_UPtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us load an image\n",
        "# image_path = 'https://raw.githubusercontent.com/pytorch/serve/refs/heads/master/examples/image_classifier/kitten.jpg'  # Replace with your image path or URL\n",
        "image_path = 'https://www.pixelstalk.net/wp-content/uploads/2016/03/Animals-baby-cat-dog-HD-wallpaper.jpg'\n",
        "img = load_image(image_path, display=True)"
      ],
      "metadata": {
        "id": "-Yoa8V8OAs00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NYMerRDcUM_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the image using features from the first layer\n",
        "if gpu:\n",
        "  img = img.cuda()\n",
        "invimg = invert_image(model, img, 0, 0,0,0.1, iterations=1000)\n",
        "plt.imshow(invimg)"
      ],
      "metadata": {
        "id": "hKdEs15QUNdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try for all the convolution layers. I have some values for alpha_lambda and tv_lambda I have figured out earlier"
      ],
      "metadata": {
        "id": "V0vsQHRggbDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convlayers = [0,2,5,7,10,12,14,17,19,21,24,26,28]\n",
        "tvparams = [0,0,1e-6,1e-4,1e-4,1e-2,1e-2,1e-2,1e-2,1e-3,1e-3,1e-4,1e-5]\n",
        "alphaparams = [0,0,0,1e-6,1e-6,1e-4,1e-4,1e-5,1e-5,1e-4,1e-4,1e-5,0]\n",
        "if gpu:\n",
        "  img = img.cuda\n",
        "for i in range(len(convlayers)):\n",
        "  print('Layer ', convlayers[i])\n",
        "  plt.imshow(invert_image(model, img,convlayers[i], alphaparams[i], tvparams[i], 0.1  ))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "CGfdRaewWchx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "1. Try with different images\n",
        "2. Try changing the alpha_lambda and tv_lambda values and getting better results for the higher layers"
      ],
      "metadata": {
        "id": "vbJWrKMVhWJx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhyahbOIii2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
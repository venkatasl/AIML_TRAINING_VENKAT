{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatasl/AIML_TRAINING_VENKAT/blob/venkat_creation/DRDO2024_FeatureVisualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Visualization\n",
        "\n",
        "What do the different convolutional filters of a model represent? In this notebook, we find out by visualizing the filters."
      ],
      "metadata": {
        "id": "gnSoLreJtPY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrh-UAD3sUxz"
      },
      "outputs": [],
      "source": [
        "# import everything\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.v2 as v2\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "gpu = False # turn to True if using a gpu kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# put the model on the gpu\n",
        "if gpu:\n",
        "  model.cuda()\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "_hbyAm2Nte7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 has 39 layers in total. Let us write a function to propagate an input forward to the desired layer and get the features from there.\n",
        "\n"
      ],
      "metadata": {
        "id": "cngK9Be1uvfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(model, input, layernum):\n",
        "  index = 0\n",
        "  for layer in model.features.children():\n",
        "    input = layer(input)\n",
        "    if index==layernum:\n",
        "      return input\n",
        "    index += 1\n",
        "\n",
        "  input = model.avgpool(input)\n",
        "  if index==layernum:\n",
        "    return input\n",
        "  index += 1\n",
        "\n",
        "  input = torch.flatten(input, 1)\n",
        "\n",
        "  for layer in model.classifier.children():\n",
        "    input = layer(input)\n",
        "    if index==layernum:\n",
        "      return input\n",
        "    index += 1\n",
        "  return index # if layernum is bigger than the number of layers, it will return how many layers are there\n"
      ],
      "metadata": {
        "id": "vNIder3Puakb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define some helper functions:"
      ],
      "metadata": {
        "id": "ONxC8gM3u5uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image transformation. This is important because this is how the model was trained\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    # The below values are based on the mean and st.deviation of the ImageNet dataset\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# inverse of the preprocess transform\n",
        "inversetransform = transforms.Compose([\n",
        "        transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "    std=[1/0.229, 1/0.224, 1/0.255]),\n",
        "        transforms.ToPILImage()])"
      ],
      "metadata": {
        "id": "kujKYmY0u0QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define some loss functions nd regularizations"
      ],
      "metadata": {
        "id": "x6Tq0VBMvAKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tv(t,beta=2):\n",
        "    #gets the smoothness or the edginess of an image\n",
        "    tv_x = t[:,:,:,1:]-t[:,:,:,:-1]\n",
        "    tv_y = t[:,:,1:,:]-t[:,:,:-1,:]\n",
        "\n",
        "    tv_x = tv_x[:,:,:-1,:]\n",
        "    tv_y = tv_y[:,:,:,:-1]\n",
        "    if False: print(tv_x)\n",
        "    tv_2 = tv_x **2 + tv_y **2\n",
        "    tv = tv_2.pow(beta/2.)\n",
        "    total = tv.sum()\n",
        "    return total\n",
        "\n",
        "def tv2(t):\n",
        "    #specifically with beta =2\n",
        "    tv_x = t[:,:,:,1:]-t[:,:,:,:-1]\n",
        "    tv_y = t[:,:,1:,:]-t[:,:,:-1,:]\n",
        "\n",
        "    tv_x = tv_x[:,:,:-1,:]\n",
        "    tv_y = tv_y[:,:,:,:-1]\n",
        "    tv_x_2 = (tv_x **2).sum()\n",
        "    tv_y_2 = (tv_y **2).sum()\n",
        "\n",
        "    if False: print(tv_x)\n",
        "    tv_2 =  tv_x_2 + tv_y_2\n",
        "    total = tv_2.sum()\n",
        "    return total\n",
        "\n",
        "def alpha_norm(t,alpha=6): #Called p-norm in wikipedia\n",
        "    a = torch.sum(t.pow(alpha)) # you have to take the alpha^th root also, but it doesn't matter for optimization\n",
        "    return a\n",
        "\n",
        "# our goal is the maximize the mean of a particular filter\n",
        "def total(x_feat, x, alpha_lambda, tv_lambda ):\n",
        "    return -torch.mean(x_feat) + alpha_lambda*alpha_norm(x) + tv_lambda*tv2(x);\n",
        "\n"
      ],
      "metadata": {
        "id": "mDUMjX-Lu8UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization function:"
      ],
      "metadata": {
        "id": "lACDedC0vR_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_features(model, layer, filter, alpha_lambda, tv_lambda, lr, iterations=100):\n",
        "  # let's start with a random image\n",
        "  x = torch.rand(1,3,224,224) # this is the random image we will optimize\n",
        "  if gpu:\n",
        "    x = x.cuda()\n",
        "  x.requires_grad=True\n",
        "\n",
        "  # create an optimizer to modify the image:\n",
        "  optimizer = Adam([x], lr=0.5, weight_decay=1e-6) # create an optimizer for the image\n",
        "\n",
        "  # now the training iterations!\n",
        "  for i in range(iterations):\n",
        "    x_feats = get_features(model, x, layer)[:,filter, :,:] # select the filter we want\n",
        "    loss = total(x_feats, x, alpha_lambda, tv_lambda)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'\\r {i} of {iterations} iterations complete', end = '     ')\n",
        "\n",
        "  return inversetransform(x.squeeze().cpu())"
      ],
      "metadata": {
        "id": "n6dmROtTvT0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us run for a few filters of the 7th layer"
      ],
      "metadata": {
        "id": "g8J_VJ4NwCLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(128):\n",
        "  plt.imshow(visualize_features(model, 7 ,i, 1e-6, 1e-4, 0.01, 20))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "M2xKB_63wAkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "1. Try with differnet values for alpha_lambda and tv_lambda and lr\n",
        "2. Try for different layers. You have to change the values of alpha_lambda, tv_lambda and lr accordingly. See if you can find any recognizable patterns\n",
        "3. What happens if we change the mean for max in the loss function?"
      ],
      "metadata": {
        "id": "PPEUFjaZ4Dw4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOK4LE7E6UQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatasl/AIML_TRAINING_VENKAT/blob/venkat_creation/3_SelfAttention_Hands_On.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention\n",
        "\n",
        "Having explored attention in depth, we will now redirect our focus to self-attention. In the context of a self-attention module, it receives a certain number of inputs and produces an equal number of outputs. So, what exactly occurs within this module? Put simply, the self-attention mechanism enables the inputs to interact with each other (hence \"self\") and determine which elements deserve more attention (\"attention\"). The outputs are a result of these interactions and the corresponding attention scores, thereby representing aggregated information\n",
        "\n",
        "The primary objective of this exercise is to guide you through the mathematical operations employed in a self-attention module. Upon completing this article, you will possess the knowledge and ability to construct a self-attention module either through writing or coding it from scratch.\n",
        "\n",
        "Follow the diagram carefully to understand the details, we'll code sub sections interactively\n"
      ],
      "metadata": {
        "id": "snOcG5H7iwkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://miro.medium.com/v2/resize:fit:1400/1*_92bnsMJy8Bl539G4v93yg.gif)"
      ],
      "metadata": {
        "id": "qdu8LMJQURzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Step1: Preparing the inputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KkXeY9qbPl8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYrGupE7Ct8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420a117c-f933-4058-8af2-6a83f9c008e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 0.],\n",
            "        [0., 2., 0., 2.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = [\n",
        "  [1, 0, 1, 0], # Input 1\n",
        "  [0, 2, 0, 2], # Input 2\n",
        "  [1, 1, 1, 1]  # Input 3\n",
        " ]\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Initialise weights\n",
        "\n",
        "\n",
        "Each input in the system necessitates three representations (as depicted in the diagram below). These representations are denoted as key (orange), query (red), and value (purple). For the purpose of this example, let's assume that we desire these representations to have a dimensionality of 3. Because every input has a dimension of 4, each set of the weights must have a shape of 4×3"
      ],
      "metadata": {
        "id": "J2qKPb4tPO7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w_key = [\n",
        "  [0, 0, 1],\n",
        "  [1, 1, 0],\n",
        "  [0, 1, 0],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_query = [\n",
        "  [1, 0, 1],\n",
        "  [1, 0, 0],\n",
        "  [0, 0, 1],\n",
        "  [0, 1, 1]\n",
        "]\n",
        "w_value = [\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
        "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
        "w_value = torch.tensor(w_value, dtype=torch.float32)\n",
        "\n",
        "print(\"Weights for key: \\n\", w_key)\n",
        "print(\"Weights for query: \\n\", w_query)\n",
        "print(\"Weights for value: \\n\", w_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6daaiTuiTzq",
        "outputId": "7cc309c7-49ad-40a9-990a-26af32325d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for key: \n",
            " tensor([[0., 0., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [1., 1., 0.]])\n",
            "Weights for query: \n",
            " tensor([[1., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 1., 1.]])\n",
            "Weights for value: \n",
            " tensor([[0., 2., 0.],\n",
            "        [0., 3., 0.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Derive key, query and value\n",
        "\n",
        "Now that we have the three sets of weights, let’s actually obtain the **key**, **query** and **value** representations for every input.\n",
        "\n",
        "Computing the keys:\n",
        "```\n",
        "               [0, 0, 1]\n",
        "[1, 0, 1, 0]   [1, 1, 0]   [0, 1, 1]\n",
        "[0, 2, 0, 2] x [0, 1, 0] = [4, 4, 0]\n",
        "[1, 1, 1, 1]   [1, 1, 0]   [2, 3, 1]\n",
        "```"
      ],
      "metadata": {
        "id": "x8CsTaivQWx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = x @ w_key\n",
        "\n",
        "#TO-DO\n",
        "querys = x @ w_query\n",
        "\n",
        "#TO-DO\n",
        "values = x @ w_value\n",
        "\n",
        "print(\"Keys: \\n\", keys)\n",
        "print(\"Querys: \\n\", querys)\n",
        "print(\"Values: \\n\", values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oboxJqmjBmZ",
        "outputId": "bf11b74c-7046-4561-b163-c152ae95b254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: \n",
            " tensor([[0., 1., 1.],\n",
            "        [4., 4., 0.],\n",
            "        [2., 3., 1.]])\n",
            "Querys: \n",
            " tensor([[1., 0., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 1., 3.]])\n",
            "Values: \n",
            " tensor([[1., 2., 3.],\n",
            "        [2., 8., 0.],\n",
            "        [2., 6., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Calculate attention scores\n",
        "\n",
        "To derive attention scores, we initiate the process by computing the dot product between the query representation (red) of Input 1 and all the keys (orange), including itself. Considering that there are three key representations (due to the presence of three inputs), we generate three attention scores (depicted in blue).\n",
        "\n",
        "```\n",
        "            [0, 4, 2]\n",
        "[1, 0, 2] x [1, 4, 3] = [2, 4, 4]\n",
        "            [1, 0, 1]\n",
        "```\n",
        "We only use the query from Input 1. Later we'll work on repeating this same step for the other querys."
      ],
      "metadata": {
        "id": "2iyTGHmWQ27j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TO-DO\n",
        "attn_scores = torch.matmul(querys,keys.T)\n",
        "print(attn_scores)\n",
        "\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "#TO-DO\n",
        "attn_scores_softmax = softmax(attn_scores)\n",
        "print(attn_scores_softmax)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl2n66i7jLJ4",
        "outputId": "68b37bb0-04a4-4f42-d160-bfd68a671407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.,  4.],\n",
            "        [ 4., 16., 12.],\n",
            "        [ 4., 12., 10.]])\n",
            "tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
            "        [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
            "        [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-cf9f3ef44867>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_scores_softmax = softmax(attn_scores)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Multiply scores with values\n",
        "\n",
        "The softmaxed attention scores for each input (blue) is multiplied with its corresponding **value** (purple). This results in 3 alignment vectors (yellow). In this tutorial, we'll refer to them as **weighted values**.\n",
        "\n",
        "```\n",
        "1: 0.0 * [1, 2, 3] = [0.0, 0.0, 0.0]\n",
        "2: 0.5 * [2, 8, 0] = [1.0, 4.0, 0.0]\n",
        "3: 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5]\n",
        "```"
      ],
      "metadata": {
        "id": "TixFAYxjSHa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_softmax.unsqueeze(-1).shape"
      ],
      "metadata": {
        "id": "EkyM0RpI8W1f",
        "outputId": "ed98bedc-e29a-4b76-ab28-04e937dfc2d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TO-DO\n",
        "weighted_values = values * attn_scores_softmax.unsqueeze(-1)\n",
        "print(weighted_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B9rbo_9jhsQ",
        "outputId": "8a0476a9-2629-4ad0-e173-2bd67b1173b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[6.3379e-02, 1.2676e-01, 1.9014e-01],\n",
            "         [9.3662e-01, 3.7465e+00, 0.0000e+00],\n",
            "         [9.3662e-01, 2.8099e+00, 1.4049e+00]],\n",
            "\n",
            "        [[6.0337e-06, 1.2067e-05, 1.8101e-05],\n",
            "         [1.9640e+00, 7.8561e+00, 0.0000e+00],\n",
            "         [3.5972e-02, 1.0792e-01, 5.3958e-02]],\n",
            "\n",
            "        [[2.9539e-04, 5.9077e-04, 8.8616e-04],\n",
            "         [1.7611e+00, 7.0443e+00, 0.0000e+00],\n",
            "         [2.3834e-01, 7.1501e-01, 3.5750e-01]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Sum weighted values\n",
        "\n",
        "\n",
        "Take all the **weighted values** (yellow) and sum them element-wise:\n",
        "\n",
        "```\n",
        "  [0.0, 0.0, 0.0]\n",
        "+ [1.0, 4.0, 0.0]\n",
        "+ [1.0, 3.0, 1.5]\n",
        "-----------------\n",
        "= [2.0, 7.0, 1.5]\n",
        "```\n",
        "\n",
        "The resulting vector ```[2.0, 7.0, 1.5]``` (dark green) **is Output 1**, which is based on the **query representation from Input 1** interacting with all other keys, including itself."
      ],
      "metadata": {
        "id": "nRqF_oTESeDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TO-DO\n",
        "outputs = torch.sum(weighted_values, axis=1)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoScdLlakTbR",
        "outputId": "3aff3685-63c5-45c2-8fb9-d3458d5e2848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9366, 6.6831, 1.5951],\n",
            "        [2.0000, 7.9640, 0.0540],\n",
            "        [1.9997, 7.7599, 0.3584]])\n"
          ]
        }
      ]
    }
  ]
}